# [作业01-NLP] 许晋诚 - 金融领域特定RAG问答系统 (Pro版)

## 1. 项目概述 (Project Overview)
本项目构建了一个垂直领域的**金融年报智能问答系统**。针对通用大模型在长文本财务报告中存在的信息幻觉（Hallucination）和知识滞后问题，本项目采用了 **RAG (检索增强生成)** 架构。通过引入国产中文语义向量模型和本地向量数据库，实现了对 20+ 份、超万字长文年报的精准语义检索与可信问答。

- **独立代码仓库**：[👉 点击跳转 Financial-Report-RAG](https://github.com/XuJincheng101/Financial-Report-RAG)
- **核心特性**：
    - ⚡ **全栈开发**：后端 LangChain 0.2 (LCEL) + 前端 Streamlit Pro 交互界面。
    - 🔍 **精准检索**：基于 BAAI/bge-small-zh-v1.5 的语义匹配，Top-1 准确率显著优于基线。
    - 🛡️ **拒识机制**：通过 Prompt Engineering 有效抑制非事实性回答，支持来源溯源。

## 2. 数据来源与预处理 (Data Processing)

### 2.1 数据分布
本项目收集了 2024 年度不同行业的领军企业年报 PDF，确保数据的多样性与真实性。

| 行业分类 | 代表公司 | 文件数量 | 预估页数 |
| :--- | :--- | :---: | :---: |
| 通信运营商 | 中国电信、中国移动 | 5 | ~800页 |
| 金融银行 | 建设银行、中国平安 | 5 | ~1200页 |
| 白酒制造 | 贵州茅台、五粮液 | 5 | ~600页 |
| 科技/新能源 | 宁德时代、比亚迪 | 5 | ~750页 |
| **合计** | **跨行业多模态** | **20** | **12,000+ Chunks** |

### 2.2 数据清洗流水线 (ETL Pipeline)
为了提高检索质量，编写了自动化脚本 (`3_build_knowledge_base.py`) 执行以下步骤：
1.  **格式标准化**：利用 `pypdf` 提取文本，并通过正则去除页眉、页脚及无意义的乱码字符。
2.  **语义切分**：使用 `RecursiveCharacterTextSplitter`，设置 `chunk_size=600`，`chunk_overlap=100`。
    - *理由*：保留 100 字符重叠是为了防止关键的跨句语义（如“净利润为...”）被切断。
3.  **鲁棒性写入**：针对 ChromaDB 的写入限制，实现了 **Batch Processing (分批处理)** 算法，每批 5000 条，解决了大规模向量写入时的内存溢出问题。

## 3. 技术路线与方法 (Methodology)

### 3.1 系统架构图
  A[用户提问] --> B{Streamlit前端}
  B --> C[LangChain检索链]
  C --> D[ChromaDB向量库]
  D -- 语义检索(Top-K) --> E[相关文档片段]
  E --> F[Prompt组装]
  F --> G[通义千问LLM]
  G --> H[最终回答+来源溯源]
### 3.2 关键技术栈
LLM (生成): 通义千问 Qwen-Turbo (DashScope API)，Temperature=0 (确保严谨性)。

Embedding (索引): BAAI/bge-small-zh-v1.5。

选型理由：相比 all-MiniLM-L6-v2，BGE 针对中文语义相似度任务（STS）进行了专项微调，维度为 512 维，兼顾速度与精度。

Vector DB (存储): ChromaDB (本地持久化，无需服务器)。

Prompt Engineering (提示词工程): 采用了 "Role Play + Context Constraint" 的策略，并在代码中显式定义：
你是一个专业的金融分析师。请基于以下检索到的年报片段回答用户问题。
如果片段中没有答案，请直接说“根据现有年报无法找到相关数据”，不要编造。
<context>{context}</context>
用户提问: {input}
## 4. 实验结果与分析 (Results & Analysis)
### 4.1 模型对比实验
为了验证 Embedding 模型的效果，在“中国电信营收”、“茅台分红”等 10 个测试用例上进行了对比测试。
（<img width="930" height="193" alt="image" src="https://github.com/user-attachments/assets/92cea321-0a98-41fb-a577-8cc4ca8cc2b1" />
）
分析：基线模型 MiniLM 主要基于英文语料训练，对中文机构简称（如“建行”、“电信”）敏感度极低。切换为 BGE 中文模型后，检索准确率得到质的飞跃。
### 4.2 幻觉抑制测试
测试问题：“特斯拉2024年的净利润是多少？”（注：知识库中无特斯拉年报）

优化前：AI 可能会根据通用知识胡编一个数字。

优化后：AI 回答“根据现有年报无法找到相关数据”，并列出检索到的低相关文档（如比亚迪年报），证明拒识机制生效。
（<img width="2178" height="571" alt="image" src="https://github.com/user-attachments/assets/5500cc09-93e6-4c31-8962-f3622daa80a3" />
）
##5. 项目亮点与创新 (Highlights)
工程化落地：解决了大规模数据（>1万片段）写入向量库时的 Batch size limit exceeded 问题，实现了工业级的写入鲁棒性。

交互体验优化：开发了 Streamlit Pro 版界面，支持 流式对话、历史记录一键清空 以及 Markdown 表格渲染，用户体验接近商业级产品。

全链路可溯源：每一个回答底部均强制附带 📄 参考来源: xxx.pdf，解决了大模型在金融领域应用最大的信任难题。

## 6. 运行截图 (Demo)
下图展示了系统准确回答“中国电信”营收数据，并以表格形式回答相应问题，且底部包含精准的文件引用。
![Web UI Pro版界面]（<img width="2543" height="1296" alt="image" src="https://github.com/user-attachments/assets/1dab812a-d354-4dfa-bff4-86be03e104a3" />
<img width="2540" height="1275" alt="image" src="https://github.com/user-attachments/assets/10777810-91ac-4810-9fcf-6248d96ec35a" />
<img width="2546" height="1298" alt="image" src="https://github.com/user-attachments/assets/fe89897a-f250-4caa-816d-77c3aabde6b6" />
）
## 7. 未来改进方向
- [ ] **多模态扩展**：增加对年报中图片和表格的解析能力。
- [ ] **本地部署**：尝试使用 Ollama 部署 Llama3 替代在线 API，实现完全离线运行。





